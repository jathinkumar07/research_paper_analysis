import os
import time
import requests
import logging
import re
import random
from typing import List, Dict
import nltk

# Download punkt tokenizer data if not already present
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt', quiet=True)

logger = logging.getLogger(__name__)

# Environment variables for Google Fact Check Tools API configuration
GOOGLE_SERVICE_ACCOUNT_FILE = os.getenv("GOOGLE_FACTCHECK_SERVICE_ACCOUNT_FILE")  # path to JSON service account file
GOOGLE_API_KEY = os.getenv("GOOGLE_FACT_CHECK_API_KEY") or os.getenv("GOOGLE_API_KEY") or os.getenv("GOOGLE_FACT_CHECK_KEY")  # string API key
FACTCHECK_USE = os.getenv("FACTCHECK_USE", "api_key")  # "service_account" | "api_key" | "disabled"
FACTCHECK_TIMEOUT = float(os.getenv("FACTCHECK_TIMEOUT", "8.0"))
MAX_RETRIES = int(os.getenv("FACTCHECK_MAX_RETRIES", "3"))
DELAY_BETWEEN_CALLS = float(os.getenv("FACTCHECK_DELAY", "0.5"))


def _clean_query_for_factcheck(claim: str, max_len: int = 120) -> str:
    """
    Clean and prepare a claim query for the Google FactCheck API to prevent HTTP 400 errors.
    
    Args:
        claim: Raw claim text to clean
        max_len: Maximum length of the cleaned query (default 120)
        
    Returns:
        Cleaned query string, or empty string if claim is empty after cleaning
    """
    if not claim or not claim.strip():
        return ""
    
    # Remove newlines and normalize whitespace
    cleaned = " ".join(claim.split())
    
    # Remove control characters and non-printable characters
    cleaned = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', cleaned)
    
    # Remove problematic punctuation and quotes
    # Keep basic punctuation but remove quotes, brackets, and other special chars
    cleaned = re.sub(r'["\'\[\]{}()<>Â«Â»""''`]', '', cleaned)
    
    # Remove excessive punctuation (multiple consecutive punctuation marks)
    cleaned = re.sub(r'[.!?]{2,}', '.', cleaned)
    cleaned = re.sub(r'[,;:]{2,}', ',', cleaned)
    
    # Clean up any remaining whitespace issues
    cleaned = " ".join(cleaned.split())
    
    if not cleaned:
        return ""
    
    # Truncate to max_len, trying to cut at sentence boundary if possible
    if len(cleaned) <= max_len:
        return cleaned
    
    # Try to cut at a sentence boundary (period, exclamation, question mark)
    truncated = cleaned[:max_len]
    last_sentence_end = max(
        truncated.rfind('.'),
        truncated.rfind('!'),
        truncated.rfind('?')
    )
    
    if last_sentence_end > max_len * 0.6:  # Only cut at sentence if it's not too short
        return truncated[:last_sentence_end + 1].strip()
    else:
        # Cut at word boundary
        last_space = truncated.rfind(' ')
        if last_space > max_len * 0.8:
            return truncated[:last_space].strip()
        else:
            return truncated.strip()


def extract_claims(text: str) -> List[str]:
    """
    Extract candidate claim sentences from text using NLTK sentence tokenization.
    
    Args:
        text: Input text to extract claims from
        
    Returns:
        List of candidate claim sentences (filtered for length and limited to 20)
    """
    if not text:
        return []
    
    try:
        # Split text into sentences using NLTK
        sentences = nltk.tokenize.sent_tokenize(text)
        
        # Filter sentences that are likely to be claims
        # Keep sentences longer than 40 characters to filter out short fragments
        claims = []
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 40 and not _is_likely_non_claim(sentence):
                claims.append(sentence)
        
        # Limit to first 20 candidate claims to avoid excessive API calls
        return claims[:20]
        
    except Exception as e:
        logger.error(f"Error extracting claims: {e}")
        return []


def _is_likely_non_claim(sentence: str) -> bool:
    """
    Filter out sentences that are unlikely to be factual claims.
    
    Args:
        sentence: Sentence to evaluate
        
    Returns:
        True if sentence should be filtered out
    """
    sentence_lower = sentence.lower().strip()
    
    # Skip questions, references, citations, and other non-claim content
    skip_patterns = [
        sentence_lower.startswith(('figure', 'table', 'see', 'cf.', 'e.g.', 'i.e.')),
        sentence_lower.endswith('?'),
        '[' in sentence and ']' in sentence,  # likely citations
        sentence_lower.startswith(('references', 'bibliography', 'acknowledgments')),
        len(sentence.split()) < 5,  # very short sentences
    ]
    
    return any(skip_patterns)


def _call_google_factcheck_rest(query: str) -> Dict:
    """
    Call Google Fact Check Tools API using REST API with API key.
    
    Args:
        query: Claim text to fact-check
        
    Returns:
        API response as dictionary
        
    Raises:
        RuntimeError: If API key not configured
        requests.RequestException: If API call fails after retries
    """
    api_key = GOOGLE_API_KEY
    if not api_key:
        raise RuntimeError("GOOGLE_API_KEY not configured")
    
    # Clean the query to prevent API errors
    cleaned_query = _clean_query_for_factcheck(query)
    if not cleaned_query:
        return {"claims": []}  # Return empty result for invalid queries
    
    url = "https://factchecktools.googleapis.com/v1alpha1/claims:search"
    params = {"query": cleaned_query, "key": api_key}
    
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            response = requests.get(url, params=params, timeout=FACTCHECK_TIMEOUT)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.warning(f"Factcheck REST API error attempt {attempt}/{MAX_RETRIES}: {e}")
            if attempt < MAX_RETRIES:
                time.sleep(0.5 * attempt)  # exponential backoff
            else:
                raise


def _call_google_factcheck_service_account(service, query: str) -> Dict:
    """
    Call Google Fact Check Tools API using service account credentials.
    
    Args:
        service: Google API service client
        query: Claim text to fact-check
        
    Returns:
        API response as dictionary
    """
    # Clean the query to prevent API errors
    cleaned_query = _clean_query_for_factcheck(query)
    if not cleaned_query:
        return {"claims": []}  # Return empty result for invalid queries
    
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            request = service.claims().search(query=cleaned_query)
            response = request.execute()
            return response
        except Exception as e:
            logger.warning(f"Factcheck service account API error attempt {attempt}/{MAX_RETRIES}: {e}")
            if attempt < MAX_RETRIES:
                time.sleep(0.5 * attempt)
            else:
                raise


def fact_check_claims(claims: List[str]) -> List[Dict]:
    """
    Fact-check a list of claims using Google Fact Check Tools API.
    
    Supports two authentication modes:
    1. Service account JSON file (GOOGLE_FACTCHECK_SERVICE_ACCOUNT_FILE)
    2. Simple API key (GOOGLE_API_KEY)
    
    Args:
        claims: List of claim sentences to fact-check
        
    Returns:
        List of normalized fact-check results, one per claim:
        {
            "claim": "<original sentence>",
            "status": "verified" | "contradicted" | "no_verdict" | "api_error" | "not_configured",
            "fact_checks": [ { "text": "...", "claimReview": {...}, "url": "..." } ... ],
            "error": "<error message if any>"
        }
    """
    results = []
    if not claims:
        return results

    # Determine authentication method
    use_service_account = bool(
        GOOGLE_SERVICE_ACCOUNT_FILE and 
        os.path.exists(GOOGLE_SERVICE_ACCOUNT_FILE) and 
        FACTCHECK_USE == "service_account"
    )
    use_api_key = bool(GOOGLE_API_KEY and FACTCHECK_USE in ["api_key", "service_account"])
    
    # Check if fact-checking is disabled
    if FACTCHECK_USE == "disabled":
        for claim in claims:
            results.append({
                "claim": claim,
                "status": "not_configured",
                "fact_checks": [],
                "error": "Fact-checking is disabled via FACTCHECK_USE=disabled"
            })
        return results

    # If neither authentication method is available, use mock data
    if not use_service_account and not use_api_key:
        return _generate_mock_fact_check_results(claims)

    # Initialize service account client if available
    service = None
    call_mode = "api_key"
    
    if use_service_account:
        try:
            from google.oauth2 import service_account
            from googleapiclient.discovery import build
            
            credentials = service_account.Credentials.from_service_account_file(GOOGLE_SERVICE_ACCOUNT_FILE)
            service = build("factchecktools", "v1alpha1", credentials=credentials, cache_discovery=False)
            call_mode = "service_account"
            print("âœ… Using Google Fact Check API with service account authentication")
            logger.info("Using service account authentication for fact-checking")
            
        except Exception as e:
            logger.exception(f"Failed to initialize service account client: {e}")
            if not use_api_key:
                for claim in claims:
                    results.append({
                        "claim": claim,
                        "status": "api_error",
                        "fact_checks": [],
                        "error": f"Service account initialization error: {e}"
                    })
                return results
            call_mode = "api_key"
            print("âœ… Using Google Fact Check API with API key authentication")
            logger.info("Falling back to API key authentication")

    # Log which authentication method is being used
    if call_mode == "api_key" and not service:
        print("âœ… Using Google Fact Check API with API key authentication")
        logger.info("Using API key authentication for fact-checking")
    
    # Process each claim
    for i, claim in enumerate(claims):
        # Add delay between API calls to avoid rate limiting
        if i > 0:
            time.sleep(DELAY_BETWEEN_CALLS)
        
        # Check if claim can be cleaned for API call
        cleaned_claim = _clean_query_for_factcheck(claim)
        if not cleaned_claim:
            results.append({
                "claim": claim,
                "status": "not_configured",
                "fact_checks": [],
                "error": "Claim could not be processed (too short or invalid after cleaning)"
            })
            continue
        
        try:
            # Call appropriate API method
            if call_mode == "service_account" and service:
                response = _call_google_factcheck_service_account(service, claim)
            else:
                response = _call_google_factcheck_rest(claim)
            
            # Extract fact-check data from response
            fact_checks = response.get("claims", []) if isinstance(response, dict) else []
            
            # Determine status based on fact-check results
            status = _determine_fact_check_status(fact_checks)
            
            results.append({
                "claim": claim,
                "status": status,
                "fact_checks": fact_checks,
                "error": None
            })
            
            logger.debug(f"Fact-checked claim: {claim[:50]}... -> {status}")
            
        except Exception as e:
            logger.exception(f"Fact check API error for claim: {claim[:50]}...")
            results.append({
                "claim": claim,
                "status": "api_error",
                "fact_checks": [],
                "error": str(e)
            })

    return results


def _determine_fact_check_status(fact_checks: List[Dict]) -> str:
    """
    Determine overall fact-check status based on claim reviews.
    
    This is a simplified heuristic - in practice, you might want more
    sophisticated logic to analyze the claimReview ratings.
    
    Args:
        fact_checks: List of fact-check results from API
        
    Returns:
        Status string: "verified", "contradicted", "no_verdict", or "no_verdict"
    """
    if not fact_checks:
        return "no_verdict"
    
    # Look for claimReview data in the fact checks
    ratings = []
    for fact_check in fact_checks:
        claim_review = fact_check.get("claimReview", [])
        if isinstance(claim_review, list):
            for review in claim_review:
                rating = review.get("reviewRating", {}).get("ratingValue")
                if rating:
                    ratings.append(rating)
    
    if not ratings:
        return "no_verdict"
    
    # Simple heuristic: if we have ratings, assume there's some verdict
    # In a real implementation, you'd analyze the actual rating values
    # to determine if claims are verified or contradicted
    return "no_verdict"


def _generate_mock_fact_check_results(claims: List[str]) -> List[Dict]:
    """
    Generate mock fact-check results for testing when API keys are not available.
    
    Args:
        claims: List of claim sentences
        
    Returns:
        List of mock fact-check results matching the expected format
    """
    print("ðŸ”„ Using mock fact-check data (no API key configured)")
    logger.info("Using mock fact-check data - no Google Fact Check API key found")
    
    mock_results = []
    mock_sources = [
        "FactCheck.org", "Snopes", "PolitiFact", "Reuters Fact Check", 
        "AP Fact Check", "BBC Reality Check", "Washington Post Fact Checker"
    ]
    
    mock_verdicts = [
        {"status": "verified", "rating": "True", "explanation": "This claim is supported by credible sources and evidence."},
        {"status": "contradicted", "rating": "False", "explanation": "This claim contradicts established facts and reliable sources."},
        {"status": "no_verdict", "rating": "Unproven", "explanation": "Insufficient evidence to verify or contradict this claim."},
        {"status": "verified", "rating": "Mostly True", "explanation": "This claim is largely accurate with minor inaccuracies."},
        {"status": "contradicted", "rating": "Mostly False", "explanation": "This claim contains significant inaccuracies."},
    ]
    
    for claim in claims:
        # Randomly assign verdict (weighted toward no_verdict for realism)
        verdict_weights = [0.15, 0.15, 0.5, 0.1, 0.1]  # More no_verdict results
        verdict = random.choices(mock_verdicts, weights=verdict_weights)[0]
        
        # Generate mock fact-check data
        fact_checks = []
        
        # Sometimes generate multiple fact-checks for a claim
        num_checks = random.choices([0, 1, 2], weights=[0.4, 0.4, 0.2])[0]
        
        for i in range(num_checks):
            source = random.choice(mock_sources)
            fact_check = {
                "text": claim[:100] + "..." if len(claim) > 100 else claim,
                "claimReview": [{
                    "publisher": {
                        "name": source,
                        "site": source.lower().replace(" ", "").replace(".", "") + ".com"
                    },
                    "url": f"https://{source.lower().replace(' ', '').replace('.', '')}.com/factcheck/{random.randint(1000, 9999)}",
                    "title": f"Fact Check: {claim[:50]}{'...' if len(claim) > 50 else ''}",
                    "reviewRating": {
                        "ratingValue": verdict["rating"],
                        "ratingExplanation": verdict["explanation"],
                        "alternateName": verdict["rating"]
                    },
                    "author": {
                        "name": f"{source} Editorial Team"
                    },
                    "datePublished": "2024-01-01"
                }],
                "url": f"https://{source.lower().replace(' ', '').replace('.', '')}.com/factcheck/{random.randint(1000, 9999)}"
            }
            fact_checks.append(fact_check)
        
        mock_results.append({
            "claim": claim,
            "status": verdict["status"],
            "fact_checks": fact_checks,
            "error": None
        })
    
    return mock_results